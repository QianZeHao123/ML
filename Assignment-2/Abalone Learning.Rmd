---
title: "Machine Learning Assignment 2"
author: "Zehao Qian"
date: "`r Sys.Date()`"
output: html_document
---

# Abalone Learning

## Part 0: Install requirements and clean Env values

```{r}
# install.packages('dplyr')
# install.packages('tidyr')
# install.packages('ggplot2')
# install.packages('glmnet')
```

```{r}
# --------------------------------------------------------
# clear the environment var area
rm(list = ls())
# clear all plots
graphics.off()
# clear the console area
cat("\014")
# --------------------------------------------------------
```

## **Part 1: Data Read and Cleaning**

### Step 1 Read the Data

```{r}
library(dplyr)
# current directory
current_directory = getwd()
# read_csv
# joint file path
file = file.path(current_directory, "abalone/abalone.data")
abalone_origin = read.csv(file, header = FALSE)

# Manually set the column names
colnames(abalone_origin) =
  c(
    "Sex",
    "Length",
    "Diameter",
    "Height",
    "WholeWeight",
    "ShuckedWeight",
    "VisceraWeight",
    "ShellWeight",
    "Rings"
  )

# Display the first few rows of the dataframe to verify
head(abalone_origin)
```

### Step 2 Check if the Abalone Data Set Exist Empty Values

```{r}
any(is.na(abalone_origin))
```

## Part 2 Exploratory Data Analysis

### Step 0 Data Set

```{r}
# Add a new column 'Age' which is 'Rings' + 1.5
# Add 'Age' column and remove 'Rings' column
abalone_Age = abalone_origin %>%
  mutate(Age = Rings + 1.5) %>%
  select(-Rings)
# Convert 'Sex' to dummy variables (one-hot encoding)
# dummySex = model.matrix(~ Sex - 1, data = abalone_Age)
# Bind the dummy variables back to the original dataset (excluding the original 'Sex' column)
abalone_Age_DummySex = abalone_Age %>%
  bind_cols(model.matrix( ~ Sex - 1, data = abalone_Age)) %>%
  select(-Sex)
# Dataset without sex
abalone_Age_NoSex = abalone_Age %>% select(-Sex)
# Dataset with sex=M
abalone_Age_SexM = abalone_Age %>% filter(Sex == 'M') %>% select(-Sex)
# Dataset with sex=F
abalone_Age_SexF = abalone_Age %>% filter(Sex == 'F') %>% select(-Sex)
# Dataset with sex=I
abalone_Age_SexI = abalone_Age %>% filter(Sex == 'I') %>% select(-Sex)
```

### Step 1 Single Variable Analysis

```{r}
summary(abalone_origin)
```

```{r}
# hist
library(tidyr)
abalone_origin_long_data <- abalone_origin %>%
  pivot_longer(cols = where(is.numeric),
               names_to = "Variable",
               values_to = "Value")

ggplot(abalone_origin_long_data, aes(x = Value)) +
  geom_histogram(
    binwidth = 0.1,
    fill = "blue",
    color = "black",
    alpha = 0.7
  ) +  # Adjust binwidth as needed
  facet_wrap(~ Variable, scales = "free") +
  labs(title = "Histograms of All Variables", x = "Value", y = "Frequency") +
  theme_minimal()
```

### Step 2 Bivariate Analysis

```{r message=FALSE}
# library("ggplot2")
# library("GGally")
# ggpairs(abalone_Age_DummySex)+theme_bw()
```

### Step 3 Data Cleaning

### Step 4 Find the Best Subset

```{r}
# Best Subset Selection with one-hot encoding DataSet
library(leaps)
best_models.abalone_Age_DummySex = regsubsets(Age ~ ., data = abalone_Age_DummySex, nvmax=10)
summary(best_models.abalone_Age_DummySex)
```

```{r}
best_models.abalone_Age_NoSex = regsubsets(Age ~ ., data = abalone_Age_NoSex)
BBSsummary = summary(best_models.abalone_Age_NoSex)
BBSsummary
```

```{r}
par(mfrow = c(1,3)) # allows for 3 plots to be plotted side by side
# --------------------------------------------------------
plot(BBSsummary$cp,
     xlab = "# Predictors", #x-axis label
     ylab = "Cp", #y-axis label
     type = "l", #line plot
     lwd = 2) #line thickness

cp_min = which.min(BBSsummary$cp)

#overlay the minimum of cp on the previous plot using the points function
points(cp_min,
       BBSsummary$cp[cp_min],
       pch = 4, #cross symbol used
       col = 2, #red colour
       cex = 4, #make it bigger!
       lwd = 2) #make the cross lines thicker
# --------------------------------------------------------
plot(BBSsummary$bic,
     xlab = "# Predictors", #x-axis label
     ylab = "BIC", #y-axis label
     type = "l", #line plot
     lwd = 2) #line thickness

bic_min = which.min(BBSsummary$bic)

points(bic_min,
       BBSsummary$bic[bic_min],
       pch = 4, #cross symbol used
       col = 2, #red colour
       cex = 4, #make it bigger!
       lwd = 2) #make the cross lines thicker
# --------------------------------------------------------
plot(BBSsummary$adjr2,
     xlab = "# Predictors", #x-axis label
     ylab = "AdjR2", #y-axis label
     type = "l", #line plot
     lwd = 2) #line thickness

adjr2_max = which.max(BBSsummary$adjr2)
points(adjr2_max,
       BBSsummary$adjr2[adjr2_max],
       pch = 4, #cross symbol used
       col = 2, #red colour
       cex = 4, #make it bigger!
       lwd = 2) #make the cross lines thicker
```

## Part 3 Modeling

### Lasso, Ridge and Elastic Net Regression

#### Split the Data Set with training and testing set

```{r}
# -------------------------------------------------------------
set.seed(2024)
ind = sample(1:nrow(abalone_Age_NoSex),
             size = 800,
             replace = FALSE)
training.abalone_Age_NoSex = abalone_Age_NoSex[-ind, ]
testing.abalone_Age_NoSex = abalone_Age_NoSex[ind, ]
# -------------------------------------------------------------
set.seed(2024)
ind = sample(1:nrow(abalone_Age_SexF),
             size = 300,
             replace = FALSE)
training.abalone_Age_SexF = abalone_Age_SexF[-ind, ]
testing.abalone_Age_SexF = abalone_Age_SexF[ind, ]
# -------------------------------------------------------------
set.seed(2024)
ind = sample(1:nrow(abalone_Age_SexM),
             size = 300,
             replace = FALSE)
training.abalone_Age_SexM = abalone_Age_SexM[-ind, ]
testing.abalone_Age_SexM = abalone_Age_SexM[ind, ]
# -------------------------------------------------------------
set.seed(2024)
ind = sample(1:nrow(abalone_Age_SexI),
             size = 300,
             replace = FALSE)
training.abalone_Age_SexI = abalone_Age_SexI[-ind, ]
testing.abalone_Age_SexI = abalone_Age_SexI[ind, ]
```

```{r}
library(glmnet)
# Define the function
perform_cv_glmnet <-
  function(TrainSet, TestSet, target_var, alpha) {
    print('--------------------------------------------------')
    # Generate a sequence of lambda values
    lambdas <- 10 ^ seq(-3, 3, by = 0.05)
    # Prepare the data
    y_train <- as.matrix(TrainSet[[target_var]])
    X_train <-
      as.matrix(TrainSet[,!(names(TrainSet) %in% target_var)])
    y_test <- as.matrix(TestSet[[target_var]])
    X_test <- as.matrix(TestSet[,!(names(TestSet) %in% target_var)])
    # Fit the model using cross-validation
    cv_fit <-
      cv.glmnet(
        X_train,
        y_train,
        alpha = alpha,
        lambda = lambdas,
        nfolds = 10,
        thresh = 1e-10
      )
    # Extract the lambda that minimizes the cross-validation error
    lambda_min <- cv_fit$lambda.min
    # Extract coefficients at the best lambda
    coef_best <- coef(cv_fit, s = "lambda.min")
    # -------------------------------------------------------------
    # test on training set
    # Make predictions using the best lambda
    predictionsTrain <-
      predict(cv_fit, s = "lambda.min", newx = X_train)
    # Calculate RMSE
    RMSE_Train <- sqrt(mean((predictionsTrain - y_train) ^ 2))
    # -------------------------------------------------------------
    # test on testing set
    predictionsTest <-
      predict(cv_fit, s = "lambda.min", newx = X_test)
    # Calculate RMSE
    RMSE_Test <- sqrt(mean((predictionsTest - y_test) ^ 2))
    # -------------------------------------------------------------
    # Return the results
    result = list(
      alpha = alpha,
      lambda_min = lambda_min,
      coef_best = coef_best,
      RMSE_Train = RMSE_Train,
      RMSE_Test = RMSE_Test
    )
    print(result)
    plot(cv_fit)
  }
```

```{r}
# compare different alpha (1, 0.5, 0) with the same dataset: abalone_Age_NoSex
set.seed(2024)
perform_cv_glmnet(training.abalone_Age_NoSex,
                  testing.abalone_Age_NoSex,
                  'Age',
                  1)
perform_cv_glmnet(training.abalone_Age_NoSex,
                  testing.abalone_Age_NoSex,
                  'Age',
                  0.5)
perform_cv_glmnet(training.abalone_Age_NoSex,
                  testing.abalone_Age_NoSex,
                  'Age',
                  0)
```

```{r}
# compare same alpha (1) with different datase
set.seed(2024)
perform_cv_glmnet(training.abalone_Age_NoSex,
                  testing.abalone_Age_NoSex,
                  'Age',
                  1)
perform_cv_glmnet(training.abalone_Age_SexM,
                  testing.abalone_Age_SexM,
                  'Age',
                  1)
perform_cv_glmnet(training.abalone_Age_SexF,
                  testing.abalone_Age_SexF,
                  'Age',
                  1)
perform_cv_glmnet(training.abalone_Age_SexI,
                  testing.abalone_Age_SexI,
                  'Age',
                  1)
```

### Random Forest

```{r}

```

## Part 4 Model Comparison

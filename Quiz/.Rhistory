probSF = sigmoid_activation(train, GDS[[1]], GDS[[2]])
predSF = as.numeric(probSF>0.5)
table(predSF, target)
probtestGDS = sigmoid_activation(as.matrix(testing[,c("price_scale","elevation_scale","sqft_scale")]), GDS[[1]], GDS[[2]])
testGDS = as.numeric(probtestGDS>0.5)
table(testGDS, testing$in_sf)
quality_measures = function(pred, actual) {
confusion = table(pred, actual)
accuracy = sum(diag(confusion)) / sum(confusion) #accuracy - proportion of correctly classified
prec = confusion[2, 2] / sum(confusion[, 2]) # precision - positive predictive value
sens = confusion[2, 2] / sum(confusion[2, ]) # sensitivity - true positive rate
spec = confusion[1, 1] / sum(confusion[1, ]) # specificity - true negative rate
fscore = 2 * (sens * prec) / (sens + prec) #F-score - measure of predictive performance
print(c("Precision: ", prec))
print(c("Sensitivity: ", sens))
print(c("Specificity: ", spec))
print(c("F Score: ", fscore))
print(c("Accuracy: ", accuracy))
print(confusion)
}
### Perceptron
quality_measures(testSF, testing$in_sf)
### Random Forest
quality_measures(predRF, testing$in_sf)
### Sigmoid
quality_measures(testGDS, testing$in_sf)
library(torch)
# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- tensor(as.matrix(train_df), dtype = torch_float32())
# ---------------------------------------------------------------------
# clear the environment var area
rm(list = ls())
# clear all plots
graphics.off()
# clear the console area
cat("\014")
# ---------------------------------------------------------------------
x = c(1, 1, 1, 1) # all criteria met, change according to scenario
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold
activation = function(x, w, bias){
v = x %*% w  # dot product of x and w
decision = ifelse(v+bias > 0, 1, 0)
return(as.numeric(decision))
}
print(activation(x, w, bias))
all_x = as.matrix(expand.grid(0:1, 0:1, 0:1, 0:1))
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold
results = activation(all_x, w, bias)
df = data.frame(cbind(all_x, results))
df
percep_training = function(train,
target,
weight,
bias,
learning,
epochs = 10) {
epoch = 0
n_train = nrow(train)
while (TRUE) {
if (epoch > epochs) {
print(c("Training complete - too many epochs", epochs))
print(c("Weights:", weight))
print(c("Bias:", bias))
return(list(weight, bias)) # we are done, return weights and bias
}
count_errors = 0
for (i in 1:n_train) {
x_input = train[i, ]
x_target = target[i]
guess = activation(x_input, weight, bias)
error = x_target - guess
#if the perceptron guessed correctly, the error is 0.
#If the perceptron guessed incorrectly, the error is -1 or 1 and that will be direction in which the weights will be updated.
if (error != 0) {
count_errors = count_errors + 1
weight = weight + learning * error * x_input
bias = bias + learning * error
}
if (i == n_train) {
epoch = epoch + 1
}
}
if (count_errors == 0) {
print("Training complete - linearly separable")
print(c("Weights:", weight))
print(c("Bias:", bias))
return(list(weight, bias)) # we are done, return weights and bias
}
}
}
train_AND = matrix(c(0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1),
ncol = 3,
byrow = TRUE)
train_AND
w = c(0.5, 0.5)
bias = 0
learning_rate = 0.1
ttAND = percep_training(train_AND[, 1:2], train_AND[, 3], w, bias, learning_rate)
activation(train_AND[, 1:2], ttAND[[1]], ttAND[[2]])
# if you have studied circuits or comnational logic before, this will likely make sense. If you didn't, don't worry, I'm creating a LS dataset.
circuit = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1))
TF = (circuit == 1)
circ_out = as.numeric(((TF[, 1] & TF[, 2]) | ((TF[, 3] | TF[, 4]))))
circuit$out = circ_out
circ_out
all_episodes = circuit
colnames(all_episodes) = c("X1", "X2", "X3", "X4", "D")
head(all_episodes)
train = as.matrix(all_episodes[, 1:4])
target = all_episodes$D
w = c(0.5, 0.8, 0.2, 0.9) #you can replace this with a random vector, use runif(4)
bias = 0
learning_rate = 0.01
epoch_num = 100
ttSquid = percep_training(train, target, w, bias, learning_rate, epoch_num)
all_episodes$pred = activation(train, ttSquid[[1]], ttSquid[[2]])
#Build a confusion matrix and check how many are misclassified
all_episodes$D
all_episodes$pred
table(all_episodes$D, all_episodes$pred)
circuit8 = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1))
TF = (circuit8 == 1)
circ_out = as.numeric(((TF[, 1] &
TF[, 2]) |
((TF[, 3] | TF[, 4]))) & ((TF[, 5] &
(TF[, 6])) & (TF[, 7] | TF[, 8])))
circuit8$out = circ_out
# remove for NCC
train = as.matrix(circuit8[,1:8])
target = circ_out
w = runif(8)
bias = 0
learning_rate = 0.01
epoch_num = 1000
tt8 = percep_training(train, target, w, bias, learning_rate, epoch_num)
circuit8$pred = activation(train, tt8[[1]], tt8[[2]])
#Build a confusion matrix and check how many are misclassified
head(circuit8)
table(circuit8$out, circuit8$pred)
library(dplyr)
# current directory
current_directory = getwd()
# read_csv
# joint file path
file = file.path(current_directory, "part_1_data.csv")
houses = read.csv(file, header = TRUE)
head(houses)
# Caret implements standardization where relevation or you can specify it during pre-processing
range_fun = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
houses$price_scale = range_fun(houses$price)
houses$elevation_scale = range_fun(houses$elevation)
houses$sqft_scale = range_fun(houses$sqft)
set.seed(2024)
ind = sample(1:nrow(houses), 350) #about 75% for training
training = houses[ind, ]
testing = houses[-ind, ]
train = as.matrix(training[, c("price_scale", "elevation_scale", "sqft_scale")])
target = training$in_sf
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.01
epochs = 100
Perc_sf = percep_training(train, target, weight, bias, learning, epochs)
predSF = activation(train, Perc_sf[[1]], Perc_sf[[2]])
table(predSF, target)
testSF = activation(as.matrix(testing[, c("price_scale", "elevation_scale", "sqft_scale")]), Perc_sf[[1]], Perc_sf[[2]])
table(testSF, testing$in_sf)
library(randomForest)
set.seed(2020)
rf = randomForest(factor(in_sf) ~ price_scale + elevation_scale + sqft_scale, data = training)
rf
predRF = predict(rf, newdata = testing)
table(predRF, testing$in_sf)
sigmoid_activation = function(x, w, b){
v = x %*% w + b  # dot product of x and w
sig = 1/(1+exp(-v))
return(as.numeric(sig))
}
sig_squared_loss = function (x, y, w, b){
return(sum(0.5*(sigmoid_activation(x, w, b) - y)^2))
}
grad_w = function (w, b, x, y){
y_pred = sigmoid_activation(x, w, b)
delta_w = (y_pred - y)*y_pred*(1-y_pred)*x
return(delta_w)
}
grad_b = function(w, b, x, y){
y_pred = sigmoid_activation(x, w, b)
delta_b = (y_pred - y)*y_pred*(1-y_pred)
return(delta_b)
}
grad_desc_sigmoid = function (train, target, weight, bias, learning, epochs = 10){
for (i in 1:epochs){
dw = colSums(grad_w(weight, bias, train, target))
db = sum(grad_b(weight, bias, train, target))
weight = weight - learning*dw
bias = bias - learning*db
}
return(list(weight,bias))
}
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.001
epochs = 10000
GDS = grad_desc_sigmoid(train, target, weight, bias, learning, epochs)
probSF = sigmoid_activation(train, GDS[[1]], GDS[[2]])
predSF = as.numeric(probSF>0.5)
table(predSF, target)
probtestGDS = sigmoid_activation(as.matrix(testing[,c("price_scale","elevation_scale","sqft_scale")]), GDS[[1]], GDS[[2]])
testGDS = as.numeric(probtestGDS>0.5)
table(testGDS, testing$in_sf)
quality_measures = function(pred, actual) {
confusion = table(pred, actual)
accuracy = sum(diag(confusion)) / sum(confusion) #accuracy - proportion of correctly classified
prec = confusion[2, 2] / sum(confusion[, 2]) # precision - positive predictive value
sens = confusion[2, 2] / sum(confusion[2, ]) # sensitivity - true positive rate
spec = confusion[1, 1] / sum(confusion[1, ]) # specificity - true negative rate
fscore = 2 * (sens * prec) / (sens + prec) #F-score - measure of predictive performance
print(c("Precision: ", prec))
print(c("Sensitivity: ", sens))
print(c("Specificity: ", spec))
print(c("F Score: ", fscore))
print(c("Accuracy: ", accuracy))
print(confusion)
}
### Perceptron
quality_measures(testSF, testing$in_sf)
### Random Forest
quality_measures(predRF, testing$in_sf)
### Sigmoid
quality_measures(testGDS, testing$in_sf)
library(torch)
# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- tensor(as.matrix(train_df), dtype = torch_float32())
install_torch()
library(torch)
# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- tensor(as.matrix(train_df), dtype = torch_float32())
torch::tensor(1)
?torch
??torch
library(torch)
# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- torch_tensor(as.matrix(train_df), dtype = torch_float32())
# ---------------------------------------------------------------------
# clear the environment var area
rm(list = ls())
# clear all plots
graphics.off()
# clear the console area
cat("\014")
# ---------------------------------------------------------------------
x = c(1, 1, 1, 1) # all criteria met, change according to scenario
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold
activation = function(x, w, bias){
v = x %*% w  # dot product of x and w
decision = ifelse(v+bias > 0, 1, 0)
return(as.numeric(decision))
}
print(activation(x, w, bias))
all_x = as.matrix(expand.grid(0:1, 0:1, 0:1, 0:1))
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold
results = activation(all_x, w, bias)
df = data.frame(cbind(all_x, results))
df
percep_training = function(train,
target,
weight,
bias,
learning,
epochs = 10) {
epoch = 0
n_train = nrow(train)
while (TRUE) {
if (epoch > epochs) {
print(c("Training complete - too many epochs", epochs))
print(c("Weights:", weight))
print(c("Bias:", bias))
return(list(weight, bias)) # we are done, return weights and bias
}
count_errors = 0
for (i in 1:n_train) {
x_input = train[i, ]
x_target = target[i]
guess = activation(x_input, weight, bias)
error = x_target - guess
#if the perceptron guessed correctly, the error is 0.
#If the perceptron guessed incorrectly, the error is -1 or 1 and that will be direction in which the weights will be updated.
if (error != 0) {
count_errors = count_errors + 1
weight = weight + learning * error * x_input
bias = bias + learning * error
}
if (i == n_train) {
epoch = epoch + 1
}
}
if (count_errors == 0) {
print("Training complete - linearly separable")
print(c("Weights:", weight))
print(c("Bias:", bias))
return(list(weight, bias)) # we are done, return weights and bias
}
}
}
train_AND = matrix(c(0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1),
ncol = 3,
byrow = TRUE)
train_AND
w = c(0.5, 0.5)
bias = 0
learning_rate = 0.1
ttAND = percep_training(train_AND[, 1:2], train_AND[, 3], w, bias, learning_rate)
activation(train_AND[, 1:2], ttAND[[1]], ttAND[[2]])
# if you have studied circuits or comnational logic before, this will likely make sense. If you didn't, don't worry, I'm creating a LS dataset.
circuit = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1))
TF = (circuit == 1)
circ_out = as.numeric(((TF[, 1] & TF[, 2]) | ((TF[, 3] | TF[, 4]))))
circuit$out = circ_out
circ_out
all_episodes = circuit
colnames(all_episodes) = c("X1", "X2", "X3", "X4", "D")
head(all_episodes)
train = as.matrix(all_episodes[, 1:4])
target = all_episodes$D
w = c(0.5, 0.8, 0.2, 0.9) #you can replace this with a random vector, use runif(4)
bias = 0
learning_rate = 0.01
epoch_num = 100
ttSquid = percep_training(train, target, w, bias, learning_rate, epoch_num)
all_episodes$pred = activation(train, ttSquid[[1]], ttSquid[[2]])
#Build a confusion matrix and check how many are misclassified
all_episodes$D
all_episodes$pred
table(all_episodes$D, all_episodes$pred)
circuit8 = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1))
TF = (circuit8 == 1)
circ_out = as.numeric(((TF[, 1] &
TF[, 2]) |
((TF[, 3] | TF[, 4]))) & ((TF[, 5] &
(TF[, 6])) & (TF[, 7] | TF[, 8])))
circuit8$out = circ_out
# remove for NCC
train = as.matrix(circuit8[,1:8])
target = circ_out
w = runif(8)
bias = 0
learning_rate = 0.01
epoch_num = 1000
tt8 = percep_training(train, target, w, bias, learning_rate, epoch_num)
circuit8$pred = activation(train, tt8[[1]], tt8[[2]])
#Build a confusion matrix and check how many are misclassified
head(circuit8)
table(circuit8$out, circuit8$pred)
library(dplyr)
# current directory
current_directory = getwd()
# read_csv
# joint file path
file = file.path(current_directory, "part_1_data.csv")
houses = read.csv(file, header = TRUE)
head(houses)
# Caret implements standardization where relevation or you can specify it during pre-processing
range_fun = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
houses$price_scale = range_fun(houses$price)
houses$elevation_scale = range_fun(houses$elevation)
houses$sqft_scale = range_fun(houses$sqft)
set.seed(2024)
ind = sample(1:nrow(houses), 350) #about 75% for training
training = houses[ind, ]
testing = houses[-ind, ]
train = as.matrix(training[, c("price_scale", "elevation_scale", "sqft_scale")])
target = training$in_sf
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.01
epochs = 100
Perc_sf = percep_training(train, target, weight, bias, learning, epochs)
predSF = activation(train, Perc_sf[[1]], Perc_sf[[2]])
table(predSF, target)
testSF = activation(as.matrix(testing[, c("price_scale", "elevation_scale", "sqft_scale")]), Perc_sf[[1]], Perc_sf[[2]])
table(testSF, testing$in_sf)
library(randomForest)
set.seed(2020)
rf = randomForest(factor(in_sf) ~ price_scale + elevation_scale + sqft_scale, data = training)
rf
predRF = predict(rf, newdata = testing)
table(predRF, testing$in_sf)
sigmoid_activation = function(x, w, b){
v = x %*% w + b  # dot product of x and w
sig = 1/(1+exp(-v))
return(as.numeric(sig))
}
sig_squared_loss = function (x, y, w, b){
return(sum(0.5*(sigmoid_activation(x, w, b) - y)^2))
}
grad_w = function (w, b, x, y){
y_pred = sigmoid_activation(x, w, b)
delta_w = (y_pred - y)*y_pred*(1-y_pred)*x
return(delta_w)
}
grad_b = function(w, b, x, y){
y_pred = sigmoid_activation(x, w, b)
delta_b = (y_pred - y)*y_pred*(1-y_pred)
return(delta_b)
}
grad_desc_sigmoid = function (train, target, weight, bias, learning, epochs = 10){
for (i in 1:epochs){
dw = colSums(grad_w(weight, bias, train, target))
db = sum(grad_b(weight, bias, train, target))
weight = weight - learning*dw
bias = bias - learning*db
}
return(list(weight,bias))
}
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.001
epochs = 10000
GDS = grad_desc_sigmoid(train, target, weight, bias, learning, epochs)
probSF = sigmoid_activation(train, GDS[[1]], GDS[[2]])
predSF = as.numeric(probSF>0.5)
table(predSF, target)
probtestGDS = sigmoid_activation(as.matrix(testing[,c("price_scale","elevation_scale","sqft_scale")]), GDS[[1]], GDS[[2]])
testGDS = as.numeric(probtestGDS>0.5)
table(testGDS, testing$in_sf)
quality_measures = function(pred, actual) {
confusion = table(pred, actual)
accuracy = sum(diag(confusion)) / sum(confusion) #accuracy - proportion of correctly classified
prec = confusion[2, 2] / sum(confusion[, 2]) # precision - positive predictive value
sens = confusion[2, 2] / sum(confusion[2, ]) # sensitivity - true positive rate
spec = confusion[1, 1] / sum(confusion[1, ]) # specificity - true negative rate
fscore = 2 * (sens * prec) / (sens + prec) #F-score - measure of predictive performance
print(c("Precision: ", prec))
print(c("Sensitivity: ", sens))
print(c("Specificity: ", spec))
print(c("F Score: ", fscore))
print(c("Accuracy: ", accuracy))
print(confusion)
}
### Perceptron
quality_measures(testSF, testing$in_sf)
### Random Forest
quality_measures(predRF, testing$in_sf)
### Sigmoid
quality_measures(testGDS, testing$in_sf)
library(torch)
# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- torch_tensor(as.matrix(train_df), dtype = torch_float32())
cuda_is_available()
install_torch()
install.packages("torch")
install.packages("torch")
install.packages("torch")
cuda_is_available()
?torch_tensor
??torch_tensor
training
??tensor_dataset
library(torch)
?torch_tensor
# ---------------------------------------------------------------------
# clear the environment var area
rm(list = ls())
# clear all plots
graphics.off()
# clear the console area
cat("\014")
# ---------------------------------------------------------------------
## Define the data we're using
gini_data = data.frame(
X1 = c(0.135688569163904, 0.648322847206146, 0.922214232617989, 0.951245080679655,
0.206160640576854, 0.335889276582748, 0.529396213358268, 0.668579671066254,
0.21338652796112, 0.073560269549489, 0.995752517832443, 0.175867896992713,
0.241640011314303, 0.506603463552892, 0.719284313032404, 0.563963615568355,
0.991943622706458, 0.99151489068754, 0.604511487996206, 0.78610852221027),
X2 = c(0.337503112154081, 0.190078672720119, 0.329314273549244, 0.100072123110294,
0.579054382629693, 0.30152944708243, 0.596130579710007, 0.36300328024663,
0.747552181128412, 0.0690255162771791, 0.762068871408701, 0.780417416244745,
0.964543060166761, 0.0722105156164616, 0.375545557588339, 0.671495763584971,
0.64997500507161, 0.714535766281188, 0.968435753136873, 0.534191880607978),
X3 = c(1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2)
)
## Define a function to calculate the gini impurity
# The function takes a dataset, binary response variable (category), feature variable, and a split location (slice)
# and returns the impurity. The details are not important!
gini_impurity = function(data = gini_data,
category = "X3",
feature,
slice) {
2 / nrow(data) * (
sum(data[, feature] < slice) * mean(data[data[, feature] < slice, category] == 1) * mean(data[data[, feature] <
slice, category] != 1) +
sum(data[, feature] >= slice) * mean(data[data[feature] >= slice, category] == 1) * mean(data[data[, feature] >= slice, category] != 1)
)
}
gini_impurity(data = gini_data, category = "X3", feature = "X1", slice = 0.4)
gini_impurity(gini_data, "X3", "X1", 0.75)
gini_impurity(gini_data, "X3", "X2", 0.1)
gini_impurity(gini_data, "X3", "X2", 1/pi)
gini_impurity(gini_data, "X3", "X1", 0.2)
gini_impurity(gini_data, "X3", "X2", 0.8)
gini_impurity(gini_data, "X3", "X2", 0.5)
gini_impurity(gini_data, "X3", "X1", 0.5)

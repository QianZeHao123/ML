#### MATH42815 - Machine Learning - 2023/24

## Machine Learning - Workshop 10

**Aim**:

![title](https://imgs.xkcd.com/comics/machine_learning.png)

And that's essentially how neural networks work.

### **Perceptrons**

The **perceptron** is a binary classification algorithm; it is the simplest neural network model.

The perceptron has a single node or neuron, the neuron:

1.  takes a number of binary **inputs**, say $x_1, x_2, \ldots, x_n$,

2.  weights them according to a set of **weights** $w_1, w_2, \ldots, w_n$ - weights show the **strength** of each node,

3.  computes the dot product between those two vectors as $v = w_1x_1 + w_2x_2 + \ldots + w_nx_n$,

4.  if $v$ is bigger than a **threshold** $t$, it returns 1. Otherwise, it returns 0. This can be written as a function, also called the **activation** function:

$$
f(v) = \cases{1, & if v>t\\ 0, & if v$\leq$ t}.
$$

Another way to write the function above is to move the threshold to the right size of the inequality. We also define **bias = - threshold** and write:

$$
f(v) = \cases{1, & if v - t > 0\\ 0, & if v - t $\leq$ 0} = \cases{1, & if v+ b > 0\\ 0, & if v + b $\leq$ 0}
$$

**Example:** It is Monday. Squidward is trying to decide whether to go to work or not. His decision is likely to be affected by certain criteria such as whether Spongebob will be there or not, whether Patrick has kept him up all night or not, and so on.

Once all the criteria have been mapped to a corresponding binary variable, weights are assigned according to the **strength** of each node.

| Node  | Criteria                      | Input ($x_i$) | Weight ($w_i$) |
|-------|-------------------------------|---------------|----------------|
| $x_1$ | Spongebob is on holiday       | 0 or 1        | 0.5            |
| $x_2$ | Slept well                    | 0 or 1        | 0.8            |
| $x_3$ | Needs money to fix clarinet   | 0 or 1        | 0.2            |
| $x_4$ | Mr. Krabs will pay his salary | 0 or 1        | 0.9            |

Say today all the criteria above are met and $x_1 = x_2 = x_3 = x_4 = 1$.

We compute

$$v = x_1 w_1 + x_2w_2 + x_3 w_3 + x_4 w_4 = 0.5 + 0.8 + 0.2 + 0.9 = 2.4$$

We now need to **activate** the output. Before we do that, a **threshold** value needs to be set for which Squidward would go to work if the output is above that certain threshold. Say the threshold in this case is 2.

The activation function can be written as:

$$
f(v) = \cases{1, & if v> 2\\ 0, & if v$\leq$ 2}.
$$

So, in this case, if all the criteria in our table are met, Squidward will go to work since 2.4\>2.

However, if Spongebob is not on holiday, our model would lead to Squidward not going to work but we have plenty of evidence in the past 25 years that Squidward will go to work even if he knows Spongebob will be there. So it is likely that $w_1$ is higher than it should be or that the threshold is too low.

It could be that those criteria interact with each other and that wouldn't be captured in this decision framework.

Let's code the situation above:

```{r}
# ---------------------------------------------------------------------
# clear the environment var area
rm(list = ls())
# clear all plots
graphics.off()
# clear the console area
cat("\014")
# ---------------------------------------------------------------------
```

```{r}
x = c(1, 1, 1, 1) # all criteria met, change according to scenario
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold

activation = function(x, w, bias){
  v = x %*% w  # dot product of x and w
  decision = ifelse(v+bias > 0, 1, 0)
  return(as.numeric(decision))
}

print(activation(x, w, bias))
```

There are 16 potential scenarios in this example, let's take a look at how often they lead to a positive outcome (assuming Squidward going to work is a positive thing):

```{r}
all_x = as.matrix(expand.grid(0:1, 0:1, 0:1, 0:1))
w = c(0.5, 0.8, 0.2, 0.9) # weights - fixed for now
bias = -2 #threshold

results = activation(all_x, w, bias)

df = data.frame(cbind(all_x, results))
df
```

As noted before, there are only two cases with the current setup that would lead to Squidward going to work $(1,1,0,1)$ and $(1,1,1,1)$. Maybe the weights we have are wrong or the threshold is too high or we don't have enough criteria to make this decision. The first two problems can potentially be addressed with training and tuning.

### **Training a perceptron**

To train the perceptron, we need to define the error and its learning rate.

-   The **error** is defined as the difference between the **desired** or correct output and the model output. In our case, if the error is zero then the perceptron made the correct decision.

-   The **learning rate** controls the size of the step we will take to move. Like in the gradient descent algorithm you coded in Week 1. If the rate is too high, you might jump around your target space and miss an optimum point. If the rate is too low, the algorithm will take too long to converge.

If a training point $x$ is misclassified, we update the weights and the bias used in our activation function according to the following equations:

$$w_{new} = w_{old} + error \times learning \times x \\
b_{new} = b_{old} + error \times learning.$$

Now we need to specify the stopping criteria for the training process. These are the two most commonly used:

-   **Stopping criteria 1:** all training samples were correctly classified.

-   **Stopping criteria 2:** A set number of **epochs** have passed.

The first stopping criteria can only be achieved if the data is **linearly separable**, that means that it is possible to draw lines and planes that separate our space perfectly. This is unlikely to happen but a nice thing to aim for.

The second criteria is based on how many times the training algorithm has seen the training data.

**Exercise:** Comment the function below and identify the key building blocks used above:

```{r}
percep_training = function(train,
                           target,
                           weight,
                           bias,
                           learning,
                           epochs = 10) {
  epoch = 0
  n_train = nrow(train)
  
  while (TRUE) {
    if (epoch > epochs) {
      print(c("Training complete - too many epochs", epochs))
      print(c("Weights:", weight))
      print(c("Bias:", bias))
      return(list(weight, bias)) # we are done, return weights and bias
    }
    count_errors = 0
    for (i in 1:n_train) {
      x_input = train[i, ]
      x_target = target[i]
      guess = activation(x_input, weight, bias)
      error = x_target - guess 
      #if the perceptron guessed correctly, the error is 0.
      #If the perceptron guessed incorrectly, the error is -1 or 1 and that will be direction in which the weights will be updated.
      if (error != 0) {
        count_errors = count_errors + 1
        weight = weight + learning * error * x_input
        bias = bias + learning * error
      }
      if (i == n_train) {
        epoch = epoch + 1
      }
    }
    if (count_errors == 0) {
      print("Training complete - linearly separable")
      print(c("Weights:", weight))
      print(c("Bias:", bias))
      return(list(weight, bias)) # we are done, return weights and bias
    }
  }
}

```

Before we move back to Spongebob's problem, let's create a simple test for our function. The training set below is called the **AND** dataset, it mimics the logical operator **AND** and it is linearly separable.

```{r}
train_AND = matrix(c(0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1),
                   ncol = 3,
                   byrow = TRUE)
train_AND
w = c(0.5, 0.5)
bias = 0
learning_rate = 0.1
ttAND = percep_training(train_AND[, 1:2], train_AND[, 3], w, bias, learning_rate)
```

```{r}
activation(train_AND[, 1:2], ttAND[[1]], ttAND[[2]])
```

Say we have watched 16 episodes of Spongebob (we didn't!) and annotated them according to each of the 4 criteria listed and the outcome.

```{r}
# if you have studied circuits or comnational logic before, this will likely make sense. If you didn't, don't worry, I'm creating a LS dataset.
circuit = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1))
TF = (circuit == 1)
circ_out = as.numeric(((TF[, 1] & TF[, 2]) | ((TF[, 3] | TF[, 4]))))
circuit$out = circ_out

```

```{r}
circ_out
```

```{r}
all_episodes = circuit
colnames(all_episodes) = c("X1", "X2", "X3", "X4", "D")
head(all_episodes)
```

Now let's see what happens when we train the perceptron in a sample from the Squidward dataset we created. Let's use all observations to train our perceptron, pick a set of starting weights, and a starting bias:

```{r}
train = as.matrix(all_episodes[, 1:4])
target = all_episodes$D
w = c(0.5, 0.8, 0.2, 0.9) #you can replace this with a random vector, use runif(4)
bias = 0
learning_rate = 0.01
epoch_num = 100
```

```{r}
ttSquid = percep_training(train, target, w, bias, learning_rate, epoch_num)
```

```{r}
all_episodes$pred = activation(train, ttSquid[[1]], ttSquid[[2]])
#Build a confusion matrix and check how many are misclassified
all_episodes$D
all_episodes$pred
table(all_episodes$D, all_episodes$pred)

```

**Exercise:** It looks like we have misclassified a few training samples. Try tuning the learning rate and the number of epochs. The dataset we used for training above is linearly separable by design so you should be able to find values for these two parameters that return a "perfect" fit.

**Exercise:** If you want to practice a bit more before moving to the next part, try training and tuning a perceptron with the dataset below.

```{r}
circuit8 = as.data.frame(expand.grid(0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1, 0:1))
TF = (circuit8 == 1)
circ_out = as.numeric(((TF[, 1] &
                          TF[, 2]) |
                         ((TF[, 3] | TF[, 4]))) & ((TF[, 5] &
                                                      (TF[, 6])) & (TF[, 7] | TF[, 8])))
circuit8$out = circ_out
```

```{r}
# remove for NCC
train = as.matrix(circuit8[,1:8])
target = circ_out
w = runif(8)
bias = 0
learning_rate = 0.01
epoch_num = 1000
tt8 = percep_training(train, target, w, bias, learning_rate, epoch_num)
circuit8$pred = activation(train, tt8[[1]], tt8[[2]])
#Build a confusion matrix and check how many are misclassified
head(circuit8)
table(circuit8$out, circuit8$pred)
```

### **Perceptron with numeric inputs**

The perceptron can be extended to take numerical inputs instead of just binary ones. The output must still be binary for it to be classed as a perceptron.

Let's use the San Francisco/New York housing dataset we used in Week 3 and try to train a perceptron to predict whether a property is in San Francisco or not based on *elevation*, *price*, and *sqft*. So we have better control over the weights, we are going to scale both features.

```{r}
library(dplyr)
# current directory
current_directory = getwd()
# read_csv
# joint file path
file = file.path(current_directory, "part_1_data.csv")
houses = read.csv(file, header = TRUE)
head(houses)
```

```{r}
# Caret implements standardization where relevation or you can specify it during pre-processing
range_fun = function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}
houses$price_scale = range_fun(houses$price)
houses$elevation_scale = range_fun(houses$elevation)
houses$sqft_scale = range_fun(houses$sqft)
set.seed(2024)
ind = sample(1:nrow(houses), 350) #about 75% for training
training = houses[ind, ]
testing = houses[-ind, ]

train = as.matrix(training[, c("price_scale", "elevation_scale", "sqft_scale")])
target = training$in_sf
```

```{r}
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.01
epochs = 100
Perc_sf = percep_training(train, target, weight, bias, learning, epochs)
```

```{r}
predSF = activation(train, Perc_sf[[1]], Perc_sf[[2]])
table(predSF, target)
```

Once we have tuned the percepetron, we can check its performance on the test dataset:

```{r}
testSF = activation(as.matrix(testing[, c("price_scale", "elevation_scale", "sqft_scale")]), Perc_sf[[1]], Perc_sf[[2]])
table(testSF, testing$in_sf)
```

**Exercise:** The snippet below gives us a random forest for comparison. Try tuning your perceptron and see how close you can get to the performance of this random forest.

```{r}
library(randomForest)
set.seed(2020)
rf = randomForest(factor(in_sf) ~ price_scale + elevation_scale + sqft_scale, data = training)
rf
predRF = predict(rf, newdata = testing)
table(predRF, testing$in_sf)
```

### **Activation functions**

The activation function we have used on the perceptron is called a **binary step**. There are many other functions that are used to mimic different behaviours such as creating non-binary outputs, and addressing nonlinearity. The **sigmoid** is the most common of these functions and it is used to create a **sigmoid neuron**.

The perceptron as we have seen is a powerful neuron that can be chained with other perceptrons to create a larger network. However, a small change to weights or input values, can lead to a change in classification (from 0 to 1) during the training process without capturing nuances that may exist around the threshold point. The sigmoid (analogue to the logistic regression) gives us a smooth transition from 0 to 1.

We also have to overcome the issue related to linearly separable problems that activation functions such as the sigmoid start to address. The plot below shows the **step** function in blue and the **sigmoid** in green.

<img src="https://raw.githubusercontent.com/ccscaiado/MLRepo/main/activation.png" width="30%"/>

Unlike the perceptron where we compare the classification output at a given training point and decide whether to update the weights and bias if the point is misclassified, in the sigmoid neuron we are trying to minimize squared errors. And since we are minimizing a smooth function, we can be more targeted with how we move through the parameter space to optimize weights and bias by using a gradient descent type algorithm.

The **loss** function we are trying to minimize is given by:

$$L(w,b) = \frac{1}{2}\left(f_{w,b}(x) - y\right)^2$$

where

$$f_{w,b}(x) = \frac{1}{1+\exp(-w x + b)}$$

$w$ is a weight vector, $b$ is the bias, $x$ is the input, and $y$ is the "real" observed response.

For the gradient descent, you can either use the partial derivative approximation function from Week 2, or you can compute them analytically. If you choose to do so, you should find:

$$\Delta w = \sum_{i=1}^n(f_{w,b}(x_i) - y_i)\cdot (f_{w,b}(x_i))\cdot (1-f_{w,b}(x_i)) \cdot x_i $$

and

$$\Delta b = \sum_{i=1}^n (f_{w,b}(x_i) - y_i)\cdot (f_{w,b}(x_i))\cdot (1-f_{w,b}(x_i)). $$

First we pre-define the functions above:

```{r}
sigmoid_activation = function(x, w, b){
  v = x %*% w + b  # dot product of x and w
  sig = 1/(1+exp(-v))
  return(as.numeric(sig))
}

sig_squared_loss = function (x, y, w, b){
  return(sum(0.5*(sigmoid_activation(x, w, b) - y)^2))
}

grad_w = function (w, b, x, y){
  y_pred = sigmoid_activation(x, w, b)
  delta_w = (y_pred - y)*y_pred*(1-y_pred)*x
  return(delta_w)
}

grad_b = function(w, b, x, y){
  y_pred = sigmoid_activation(x, w, b)
  delta_b = (y_pred - y)*y_pred*(1-y_pred)
  return(delta_b)
}

```

And now we use those blocks to create our gradient descent. This is a much simpler version of the gradient descent than the one you have seen before with only one stopping criteria based on number of epochs. You could add a second stopping criteria based on the level of change in $(w,b)$. As is, the algorithm is quite cheap computationally so adding another layer of complexity might be unnecessary.

This is the simplest version of **Backpropagation**. We have assessed the quality of our neuron, estimated loss, and backpropagated this information by updating our weights and bias before repeating this process.

```{r}
grad_desc_sigmoid = function (train, target, weight, bias, learning, epochs = 10){
  for (i in 1:epochs){
    dw = colSums(grad_w(weight, bias, train, target))
    db = sum(grad_b(weight, bias, train, target))

    weight = weight - learning*dw
    bias = bias - learning*db
  }
  return(list(weight,bias))
}
```

Note that the activation function returns values in $(0,1)$ instead of a binary output. As it is seen in the output of a logistic regression, these are estimated probabilities that a given observation is in the positive class. The model here has already been tuned so that a cutoff of 0.5 is appropriate (that's why we updated the bias in our descent).

We

1.  return the tuned weights and bias from *grad_desc_sigmoid*,
2.  use the sigmoid activation function with the testing data and tuned parameters to return the estimated probabilities that each property in the testing set is in San Francisco,
3.  if the estimated probability is above 0.5, we classify the point as being in San Franscisco, and New York otherwise,
4.  build a confusion matrix to evaluate our model.

```{r}
weight = c(0.5,0.5,0.5)
bias = 0
learning = 0.001
epochs = 10000
GDS = grad_desc_sigmoid(train, target, weight, bias, learning, epochs)
probSF = sigmoid_activation(train, GDS[[1]], GDS[[2]])
predSF = as.numeric(probSF>0.5)
table(predSF, target)
```

```{r}
probtestGDS = sigmoid_activation(as.matrix(testing[,c("price_scale","elevation_scale","sqft_scale")]), GDS[[1]], GDS[[2]])
testGDS = as.numeric(probtestGDS>0.5)
table(testGDS, testing$in_sf)
```

Here is a function that computes some basic measures for monitoring the quality of a classifier. Caret has most of those already built-in as part of its output. The random forest is likely to be the best out of the 3 models we have developed so far. Use the calls below to keep track of how well your neural nets are performing.

```{r}
quality_measures = function(pred, actual) {
  confusion = table(pred, actual)
  accuracy = sum(diag(confusion)) / sum(confusion) #accuracy - proportion of correctly classified
  prec = confusion[2, 2] / sum(confusion[, 2]) # precision - positive predictive value
  sens = confusion[2, 2] / sum(confusion[2, ]) # sensitivity - true positive rate
  spec = confusion[1, 1] / sum(confusion[1, ]) # specificity - true negative rate
  fscore = 2 * (sens * prec) / (sens + prec) #F-score - measure of predictive performance
  print(c("Precision: ", prec))
  print(c("Sensitivity: ", sens))
  print(c("Specificity: ", spec))
  print(c("F Score: ", fscore))
  print(c("Accuracy: ", accuracy))
  print(confusion)
}
```

```{r}
### Perceptron
quality_measures(testSF, testing$in_sf)
```

```{r}
### Random Forest
quality_measures(predRF, testing$in_sf)
```

```{r}
### Sigmoid
quality_measures(testGDS, testing$in_sf)
```

### **Hidden Layers**

The neural nets we have coded so far had two layers: an input layer, and an output layer where the activation happens. We should now try to introduce another layer to our network that takes our inputs, apply a transformation to them, and then feeds them to the output layer. This new layer is called a **hidden** layer.

You will need:

-   Weight vectors: $w_1$ and $w_2$ randomly selected
-   learning rate
-   Bias: $b_1$ and $b_2$
-   Activation functions: $f_1$ and $f_2$

1.  Input layer: Start with an input layer $x$, calculate $w_1 \cdot x + b_1$
2.  Hidden layer: Activate $w_1 \cdot x + b_1$ using $f_1$ so that $v = f_1(w_1\cdot x + b_1)$
3.  Output layer: Activate $w_2 \cdot v + b_2$ using $f_2$

Use an optimization algorithm such as gradient descent to backward propagate and tune $w_1$, $w_2$, $b_1$ and $b_2$. Once all epochs have passed and/or your optimization step has converged, return the labels for each point.

You are welcome to continue trying to code your neural networks by hand. Each block tends to be quite simple to work through but the tuning of the network parameters can become quite cumbersome. In the next workshop, we will introduce the **torch** library, the equivalent of **pytorch** for R.

**Exercise:** Change the features used in your neurons and try to tune the hyperparameters. How close can you get to the performance of the equivalent random forest?

If you got to this point and are curious, you can start checking how **torch** works!

```{r}
library(torch)

# Assuming you have data frames 'train_df' and 'test_df'
train_tensor <- torch_tensor(as.matrix(training), dtype = torch_float32())
test_tensor <- torch_tensor(as.matrix(testing), dtype = torch_float32())

# Create datasets and dataloaders
# train_dataset <- tensor_dataset(train_tensor)
# test_dataset <- tensor_dataset(test_tensor)

# train_dataloader <- dataloader(train_dataset, batch_size = 64, shuffle = TRUE)
# test_dataloader <- dataloader(test_dataset, batch_size = 64)

```
